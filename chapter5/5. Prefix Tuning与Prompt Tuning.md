
## 5. Prefix Tuning与Prompt Tuning

### 5.1 Prefix Tuning的原理

Prefix Tuning采用了一种完全不同的思路：**不修改模型参数，而是在输入序列前添加可训练的"前缀"向量**。这些前缀向量在每一层都会影响模型的计算，相当于给模型提供了任务特定的上下文。

Prefix Tuning的工作方式是：为每一层的key和value添加可训练的前缀。在注意力计算时，这些前缀会参与到注意力机制中，影响模型对输入的理解和处理。由于前缀在每一层都起作用，它可以深度地影响模型的行为。

Prefix Tuning的**参数量非常少**。假设前缀长度为10，模型有32层，隐藏维度768，那么总参数量约为10×32×2×768≈49万，远少于全量微调的数十亿参数。

### 5.2 Prompt Tuning：更简化的方案

Prompt Tuning是Prefix Tuning的简化版本，它**只在输入层添加可训练的soft prompts**，不在每一层都添加。这使得Prompt Tuning的参数量更少，训练更简单，但表达能力也相对较弱。

Prompt Tuning特别适合生成类任务，如文本生成、摘要、翻译等。它的优势是极致的参数效率和训练速度，劣势是对复杂任务的适配能力有限。

### 5.3 Prefix/Prompt Tuning的使用场景

这两种方法适合以下场景：首先是**资源极度受限**的情况，当你只有很少的GPU资源或训练时间时，这些方法可以快速获得一定的效果提升。其次是**需要训练大量任务**的情况，由于参数量极少，可以为每个任务训练一个独立的prefix/prompt，存储和管理成本很低。第三是**生成类任务**，这些方法在生成任务上往往表现不错。

然而，对于复杂的理解类任务或需要深度调整模型行为的任务，这些方法可能不够强大，建议使用LoRA或Adapter。
