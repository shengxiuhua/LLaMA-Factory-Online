
## 2. Learning Rate (学习率) 设置技巧

### 2.1 学习率的本质与影响机制

学习率是控制模型参数更新幅度的关键超参数，它直接影响训练的收敛速度和最终性能。在大模型微调中，学习率的设置尤为关键，因为我们需要在保持预训练知识和学习新任务之间找到平衡。

**学习率过大的问题**：会导致参数更新步长过大，可能跳过最优解，甚至导致训练发散。在微调场景下，过大的学习率还可能破坏预训练模型已经学到的有用特征。

**学习率过小的问题**：会导致训练收敛缓慢，可能陷入局部最优解，或者在有限的训练时间内无法充分学习新任务。

**微调中的学习率特点**：相比从头训练，微调通常使用更小的学习率，因为预训练模型已经在一个相对较好的参数空间中，只需要进行微调整。典型的微调学习率比预训练学习率小1-2个数量级。

```python
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup

class LearningRateScheduler:
    """学习率调度器"""
    
    def __init__(self, optimizer, scheduler_type='linear', **kwargs):
        self.optimizer = optimizer
        self.scheduler_type = scheduler_type
        self.scheduler = self._create_scheduler(**kwargs)
        self.lr_history = []
    
    def _create_scheduler(self, **kwargs):
        """创建学习率调度器"""
        if self.scheduler_type == 'linear':
            return get_linear_schedule_with_warmup(
                self.optimizer,
                num_warmup_steps=kwargs.get('num_warmup_steps', 0),
                num_training_steps=kwargs.get('num_training_steps', 1000)
            )
        elif self.scheduler_type == 'cosine':
            return get_cosine_schedule_with_warmup(
                self.optimizer,
                num_warmup_steps=kwargs.get('num_warmup_steps', 0),
                num_training_steps=kwargs.get('num_training_steps', 1000)
            )
        elif self.scheduler_type == 'exponential':
            return torch.optim.lr_scheduler.ExponentialLR(
                self.optimizer,
                gamma=kwargs.get('gamma', 0.95)
            )
        elif self.scheduler_type == 'step':
            return torch.optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=kwargs.get('step_size', 100),
                gamma=kwargs.get('gamma', 0.1)
            )
        else:
            return None
    
    def step(self):
        """更新学习率"""
        if self.scheduler:
            self.scheduler.step()
        
        # 记录当前学习率
        current_lr = self.optimizer.param_groups[0]['lr']
        self.lr_history.append(current_lr)
    
    def get_current_lr(self):
        """获取当前学习率"""
        return self.optimizer.param_groups[0]['lr']
    
    def plot_lr_schedule(self, steps=None):
        """绘制学习率变化曲线"""
        if steps is None:
            steps = range(len(self.lr_history))
        
        plt.figure(figsize=(10, 6))
        plt.plot(steps, self.lr_history)
        plt.xlabel('Training Steps')
        plt.ylabel('Learning Rate')
        plt.title(f'{self.scheduler_type.capitalize()} Learning Rate Schedule')
        plt.grid(True)
        plt.show()

class LearningRateFinder:
    """学习率寻找器"""
    
    def __init__(self, model, optimizer, criterion, device):
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device
    
    def find_lr(self, train_loader, start_lr=1e-7, end_lr=10, num_iter=100):
        """寻找最优学习率"""
        # 保存原始状态
        original_state = self.model.state_dict()
        original_optimizer_state = self.optimizer.state_dict()
        
        # 设置学习率范围
        lr_mult = (end_lr / start_lr) ** (1 / num_iter)
        lr = start_lr
        self.optimizer.param_groups[0]['lr'] = lr
        
        # 记录数据
        lrs = []
        losses = []
        
        # 训练循环
        self.model.train()
        for i, (inputs, targets) in enumerate(train_loader):
            if i >= num_iter:
                break
            
            inputs, targets = inputs.to(self.device), targets.to(self.device)
            
            # 前向传播
            outputs = self.model(inputs)
            loss = self.criterion(outputs, targets)
            
            # 记录
            lrs.append(lr)
            losses.append(loss.item())
            
            # 反向传播
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            # 更新学习率
            lr *= lr_mult
            self.optimizer.param_groups[0]['lr'] = lr
        
        # 恢复原始状态
        self.model.load_state_dict(original_state)
        self.optimizer.load_state_dict(original_optimizer_state)
        
        return lrs, losses
    
    def plot_lr_find(self, lrs, losses):
        """绘制学习率寻找结果"""
        plt.figure(figsize=(12, 4))
        
        # 损失vs学习率
        plt.subplot(1, 2, 1)
        plt.plot(lrs, losses)
        plt.xscale('log')
        plt.xlabel('Learning Rate')
        plt.ylabel('Loss')
        plt.title('Loss vs Learning Rate')
        plt.grid(True)
        
        # 损失变化率vs学习率
        plt.subplot(1, 2, 2)
        # 计算损失的变化率
        loss_changes = np.gradient(losses)
        plt.plot(lrs, loss_changes)
        plt.xscale('log')
        plt.xlabel('Learning Rate')
        plt.ylabel('Loss Change Rate')
        plt.title('Loss Change Rate vs Learning Rate')
        plt.grid(True)
        
        plt.tight_layout()
        plt.show()
        
        # 推荐学习率
        min_loss_idx = np.argmin(losses)
        recommended_lr = lrs[min_loss_idx] / 10  # 通常选择最小损失对应学习率的1/10
        
        print(f"推荐学习率: {recommended_lr:.2e}")
        return recommended_lr

def get_layer_wise_lr(model, base_lr=2e-5, decay_factor=0.9):
    """分层学习率设置"""
    layer_wise_params = []
    
    # 获取模型层数
    if hasattr(model, 'transformer'):
        # Transformer模型
        num_layers = len(model.transformer.h)
        
        # 为不同层设置不同学习率
        for i, layer in enumerate(model.transformer.h):
            lr = base_lr * (decay_factor ** (num_layers - i - 1))
            layer_wise_params.append({
                'params': layer.parameters(),
                'lr': lr
            })
        
        # 输出层使用基础学习率
        if hasattr(model, 'lm_head'):
            layer_wise_params.append({
                'params': model.lm_head.parameters(),
                'lr': base_lr
            })
    
    return layer_wise_params

# 使用示例
def demonstrate_lr_scheduling():
    """演示学习率调度"""
    # 创建示例模型和优化器
    model = nn.Linear(100, 10)
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
    
    # 不同类型的学习率调度器
    schedulers = {
        'linear': LearningRateScheduler(
            optimizer, 'linear', 
            num_warmup_steps=100, 
            num_training_steps=1000
        ),
        'cosine': LearningRateScheduler(
            optimizer, 'cosine',
            num_warmup_steps=100,
            num_training_steps=1000
        ),
        'exponential': LearningRateScheduler(
            optimizer, 'exponential',
            gamma=0.95
        )
    }
    
    # 模拟训练过程
    for scheduler_name, scheduler in schedulers.items():
        print(f"\n{scheduler_name.upper()} 调度器:")
        
        # 重置优化器
        for param_group in optimizer.param_groups:
            param_group['lr'] = 2e-5
        
        scheduler.lr_history = []  # 重置历史记录
        
        # 模拟1000步训练
        for step in range(1000):
            scheduler.step()
            
            if step % 200 == 0:
                print(f"Step {step}: LR = {scheduler.get_current_lr():.2e}")

# 微调任务的学习率推荐
def get_task_specific_lr(task_type, model_size, method='lora'):
    """根据任务类型推荐学习率"""
    
    base_lrs = {
        'classification': {
            'full': {'small': 2e-5, 'medium': 1e-5, 'large': 5e-6},
            'lora': {'small': 1e-4, 'medium': 5e-5, 'large': 2e-5},
            'adapter': {'small': 1e-4, 'medium': 5e-5, 'large': 2e-5}
        },
        'generation': {
            'full': {'small': 1e-5, 'medium': 5e-6, 'large': 2e-6},
            'lora': {'small': 5e-5, 'medium': 2e-5, 'large': 1e-5},
            'adapter': {'small': 5e-5, 'medium': 2e-5, 'large': 1e-5}
        },
        'qa': {
            'full': {'small': 3e-5, 'medium': 1e-5, 'large': 5e-6},
            'lora': {'small': 1e-4, 'medium': 5e-5, 'large': 2e-5},
            'adapter': {'small': 1e-4, 'medium': 5e-5, 'large': 2e-5}
        }
    }
    
    # 根据模型参数量确定大小类别
    size_category = 'small' if '1b' in model_size or '3b' in model_size else \
                   'medium' if '7b' in model_size or '13b' in model_size else 'large'
    
    recommended_lr = base_lrs.get(task_type, {}).get(method, {}).get(size_category, 2e-5)
    
    return {
        'recommended_lr': recommended_lr,
        'lr_range': (recommended_lr * 0.1, recommended_lr * 10),
        'warmup_ratio': 0.1 if method == 'full' else 0.05,
        'scheduler': 'cosine' if task_type == 'generation' else 'linear'
    }

# 使用示例
print("=== 学习率调度演示 ===")
demonstrate_lr_scheduling()

print("\n=== 任务特定学习率推荐 ===")
tasks = ['classification', 'generation', 'qa']
models = ['7b', '13b']
methods = ['full', 'lora']

for task in tasks:
    for model in models:
        for method in methods:
            lr_config = get_task_specific_lr(task, model, method)
            print(f"{task} + {model} + {method}: {lr_config['recommended_lr']:.2e}")
```

### 2.2 学习率调度策略

**Warmup策略**：在训练初期使用较小的学习率，然后逐渐增加到目标学习率。这种策略可以避免训练初期的不稳定，特别适用于大模型微调。

**线性衰减**：在warmup阶段后，学习率线性衰减到零。这是最常用的策略，简单有效。

**余弦衰减**：学习率按照余弦函数衰减，相比线性衰减，余弦衰减在训练后期提供更平滑的学习率变化。

**分层学习率**：对模型的不同层使用不同的学习率，通常底层（接近输入）使用较小的学习率，顶层（接近输出）使用较大的学习率。


### 6.1 自动化超参数搜索

手动调参虽然能够积累经验，但效率较低且容易陷入局部最优。自动化超参数搜索技术可以更系统地探索参数空间，找到更好的配置。

**网格搜索（Grid Search）**：在预定义的参数网格中穷举所有组合。适用于参数空间较小的情况。

**随机搜索（Random Search）**：在参数空间中随机采样。相比网格搜索，随机搜索在高维空间中通常更有效。

**贝叶斯优化（Bayesian Optimization）**：基于先验知识和历史实验结果，智能地选择下一组参数。适用于评估成本高的场景。

**超带算法（Hyperband）**：结合了随机搜索和早停策略，能够高效地分配计算资源。

```python
import optuna
import numpy as np
from sklearn.model_selection import cross_val_score
import joblib
from typing import Dict, Any, Callable

class HyperparameterOptimizer:
    """超参数优化器"""
    
    def __init__(self, objective_function: Callable, direction='minimize'):
        self.objective_function = objective_function
        self.direction = direction
        self.study = None
        self.best_params = None
        
    def define_search_space(self, trial):
        """定义搜索空间"""
        # 学习率搜索空间（对数尺度）
        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-3, log=True)
        
        # 批次大小搜索空间（2的幂次）
        batch_size = trial.suggest_categorical('batch_size', [4, 8, 16, 32, 64])
        
        # 训练轮数
        epochs = trial.suggest_int('epochs', 1, 10)
        
        # 预热比例
        warmup_ratio = trial.suggest_float('warmup_ratio', 0.0, 0.2)
        
        # 权重衰减
        weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-1, log=True)
        
        # LoRA特定参数（如果使用LoRA）
        lora_r = trial.suggest_categorical('lora_r', [4, 8, 16, 32, 64])
        lora_alpha = trial.suggest_categorical('lora_alpha', [8, 16, 32, 64, 128])
        lora_dropout = trial.suggest_float('lora_dropout', 0.0, 0.3)
        
        # 梯度累积步数
        gradient_accumulation_steps = trial.suggest_categorical(
            'gradient_accumulation_steps', [1, 2, 4, 8]
        )
        
        return {
            'learning_rate': learning_rate,
            'batch_size': batch_size,
            'epochs': epochs,
            'warmup_ratio': warmup_ratio,
            'weight_decay': weight_decay,
            'lora_r': lora_r,
            'lora_alpha': lora_alpha,
            'lora_dropout': lora_dropout,
            'gradient_accumulation_steps': gradient_accumulation_steps
        }
    
    def optimize(self, n_trials=50, timeout=None):
        """执行超参数优化"""
        
        def objective(trial):
            # 获取当前试验的参数
            params = self.define_search_space(trial)
            
            # 调用目标函数
            try:
                score = self.objective_function(params)
                return score
            except Exception as e:
                print(f"Trial failed with params {params}: {e}")
                # 返回一个较差的分数
                return float('inf') if self.direction == 'minimize' else float('-inf')
        
        # 创建研究对象
        self.study = optuna.create_study(direction=self.direction)
        
        # 执行优化
        self.study.optimize(objective, n_trials=n_trials, timeout=timeout)
        
        # 保存最佳参数
        self.best_params = self.study.best_params
        
        return self.best_params, self.study.best_value
    
    def get_optimization_history(self):
        """获取优化历史"""
        if self.study is None:
            return None
        
        trials = self.study.trials
        history = {
            'trial_numbers': [t.number for t in trials],
            'values': [t.value for t in trials if t.value is not None],
            'params': [t.params for t in trials]
        }
        
        return history
    
    def plot_optimization_history(self):
        """绘制优化历史"""
        if self.study is None:
            print("No optimization study found. Run optimize() first.")
            return
        
        # 使用optuna内置的可视化功能
        try:
            import optuna.visualization as vis
            
            # 优化历史
            fig1 = vis.plot_optimization_history(self.study)
            fig1.show()
            
            # 参数重要性
            fig2 = vis.plot_param_importances(self.study)
            fig2.show()
            
            # 参数关系
            fig3 = vis.plot_parallel_coordinate(self.study)
            fig3.show()
            
        except ImportError:
            print("Please install plotly for visualization: pip install plotly")

class AdaptiveLearningRateScheduler:
    """自适应学习率调度器"""
    
    def __init__(self, optimizer, patience=5, factor=0.5, min_lr=1e-7):
        self.optimizer = optimizer
        self.patience = patience
        self.factor = factor
        self.min_lr = min_lr
        self.best_loss = float('inf')
        self.wait = 0
        self.lr_history = []
        
    def step(self, val_loss):
        """根据验证损失调整学习率"""
        current_lr = self.optimizer.param_groups[0]['lr']
        self.lr_history.append(current_lr)
        
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.wait = 0
        else:
            self.wait += 1
            
            if self.wait >= self.patience:
                new_lr = max(current_lr * self.factor, self.min_lr)
                
                if new_lr < current_lr:
                    print(f"Reducing learning rate from {current_lr:.2e} to {new_lr:.2e}")
                    
                    for param_group in self.optimizer.param_groups:
                        param_group['lr'] = new_lr
                    
                    self.wait = 0
                
                return True  # 学习率已调整
        
        return False  # 学习率未调整

def create_hyperparameter_search_example():
    """创建超参数搜索示例"""
    
    def mock_objective_function(params):
        """模拟目标函数（实际应用中这里是完整的训练和评估过程）"""
        
        # 模拟训练过程的评估指标
        # 在实际应用中，这里应该是完整的模型训练和验证过程
        
        lr = params['learning_rate']
        batch_size = params['batch_size']
        epochs = params['epochs']
        
        # 简单的模拟函数：学习率和批次大小的组合效果
        # 实际中这里应该调用真实的训练函数
        simulated_score = (
            0.1 * np.log10(lr) +  # 学习率影响
            0.05 * np.log2(batch_size) +  # 批次大小影响
            0.02 * epochs +  # 训练轮数影响
            np.random.normal(0, 0.01)  # 添加噪声
        )
        
        # 转换为准确率（0-1之间）
        accuracy = 1 / (1 + np.exp(-simulated_score))
        
        return -accuracy  # 返回负值因为我们要最小化
    
    # 创建优化器
    optimizer = HyperparameterOptimizer(mock_objective_function, direction='minimize')
    
    # 执行优化
    print("开始超参数搜索...")
    best_params, best_score = optimizer.optimize(n_trials=30)
    
    print(f"\n最佳参数: {best_params}")
    print(f"最佳分数: {-best_score:.4f}")  # 转换回正值
    
    # 获取优化历史
    history = optimizer.get_optimization_history()
    
    # 分析结果
    print(f"\n优化历史:")
    print(f"总试验次数: {len(history['trial_numbers'])}")
    print(f"最佳试验: {np.argmin(history['values'])}")
    
    return optimizer

# 运行示例
print("=== 自动化超参数搜索演示 ===")
optimizer_example = create_hyperparameter_search_example()
```

### 6.2 多目标优化

在实际应用中，我们往往需要在多个目标之间进行权衡，如准确率vs推理速度、性能vs显存使用等。多目标优化可以帮助我们找到这些目标之间的最佳平衡点。

```python
import numpy as np
from typing import List, Tuple
import matplotlib.pyplot as plt

class MultiObjectiveOptimizer:
    """多目标优化器"""
    
    def __init__(self, objectives: List[str], directions: List[str]):
        """
        objectives: 目标名称列表
        directions: 优化方向列表 ('minimize' 或 'maximize')
        """
        self.objectives = objectives
        self.directions = directions
        self.pareto_front = []
        self.all_solutions = []
    
    def is_dominated(self, solution1: Dict, solution2: Dict) -> bool:
        """检查solution1是否被solution2支配"""
        
        better_in_all = True
        better_in_at_least_one = False
        
        for obj, direction in zip(self.objectives, self.directions):
            val1 = solution1['scores'][obj]
            val2 = solution2['scores'][obj]
            
            if direction == 'minimize':
                if val1 < val2:
                    better_in_at_least_one = True
                elif val1 > val2:
                    better_in_all = False
            else:  # maximize
                if val1 > val2:
                    better_in_at_least_one = True
                elif val1 < val2:
                    better_in_all = False
        
        return better_in_all and better_in_at_least_one
    
    def update_pareto_front(self, new_solution: Dict):
        """更新帕累托前沿"""
        
        # 检查新解是否被现有解支配
        is_dominated_by_existing = False
        for existing_solution in self.pareto_front:
            if self.is_dominated(new_solution, existing_solution):
                is_dominated_by_existing = True
                break
        
        if not is_dominated_by_existing:
            # 移除被新解支配的现有解
            self.pareto_front = [
                sol for sol in self.pareto_front 
                if not self.is_dominated(sol, new_solution)
            ]
            
            # 添加新解
            self.pareto_front.append(new_solution)
        
        # 记录所有解
        self.all_solutions.append(new_solution)
    
    def optimize_multi_objective(self, objective_function: Callable, 
                                search_space_generator: Callable, 
                                n_trials: int = 100):
        """执行多目标优化"""
        
        for trial in range(n_trials):
            # 生成参数
            params = search_space_generator()
            
            try:
                # 评估多个目标
                scores = objective_function(params)
                
                solution = {
                    'params': params,
                    'scores': scores,
                    'trial': trial
                }
                
                # 更新帕累托前沿
                self.update_pareto_front(solution)
                
                if trial % 10 == 0:
                    print(f"Trial {trial}: Pareto front size = {len(self.pareto_front)}")
                    
            except Exception as e:
                print(f"Trial {trial} failed: {e}")
                continue
        
        return self.pareto_front
    
    def plot_pareto_front(self, obj1_idx: int = 0, obj2_idx: int = 1):
        """绘制帕累托前沿（二维）"""
        
        if len(self.objectives) < 2:
            print("Need at least 2 objectives for plotting")
            return
        
        obj1_name = self.objectives[obj1_idx]
        obj2_name = self.objectives[obj2_idx]
        
        # 提取所有解的目标值
        all_obj1 = [sol['scores'][obj1_name] for sol in self.all_solutions]
        all_obj2 = [sol['scores'][obj2_name] for sol in self.all_solutions]
        
        # 提取帕累托前沿的目标值
        pareto_obj1 = [sol['scores'][obj1_name] for sol in self.pareto_front]
        pareto_obj2 = [sol['scores'][obj2_name] for sol in self.pareto_front]
        
        plt.figure(figsize=(10, 8))
        
        # 绘制所有解
        plt.scatter(all_obj1, all_obj2, alpha=0.6, c='lightblue', label='All solutions')
        
        # 绘制帕累托前沿
        plt.scatter(pareto_obj1, pareto_obj2, c='red', s=100, label='Pareto front')
        
        # 连接帕累托前沿点
        if len(pareto_obj1) > 1:
            # 按第一个目标排序
            sorted_indices = np.argsort(pareto_obj1)
            sorted_obj1 = [pareto_obj1[i] for i in sorted_indices]
            sorted_obj2 = [pareto_obj2[i] for i in sorted_indices]
            plt.plot(sorted_obj1, sorted_obj2, 'r--', alpha=0.7)
        
        plt.xlabel(f'{obj1_name} ({self.directions[obj1_idx]})')
        plt.ylabel(f'{obj2_name} ({self.directions[obj2_idx]})')
        plt.title('Multi-Objective Optimization Results')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()
    
    def get_best_compromise_solution(self, weights: Dict[str, float] = None):
        """获取最佳折中解"""
        
        if not self.pareto_front:
            return None
        
        if weights is None:
            # 默认等权重
            weights = {obj: 1.0 for obj in self.objectives}
        
        best_solution = None
        best_weighted_score = float('-inf')
        
        for solution in self.pareto_front:
            weighted_score = 0
            
            for obj, direction in zip(self.objectives, self.directions):
                score = solution['scores'][obj]
                weight = weights.get(obj, 1.0)
                
                if direction == 'maximize':
                    weighted_score += weight * score
                else:  # minimize
                    weighted_score -= weight * score
            
            if weighted_score > best_weighted_score:
                best_weighted_score = weighted_score
                best_solution = solution
        
        return best_solution

def demonstrate_multi_objective_optimization():
    """演示多目标优化"""
    
    def multi_objective_function(params):
        """多目标函数：准确率 vs 推理速度 vs 显存使用"""
        
        lr = params['learning_rate']
        batch_size = params['batch_size']
        model_size = params['model_size']
        
        # 模拟准确率（要最大化）
        accuracy = 0.8 + 0.1 * np.log10(lr / 1e-5) + 0.05 * np.log2(batch_size / 8)
        accuracy = max(0.5, min(0.99, accuracy + np.random.normal(0, 0.02)))
        
        # 模拟推理速度（要最大化，这里用倒数表示时间）
        inference_speed = 100 / (model_size * batch_size**0.5)
        inference_speed = max(1, inference_speed + np.random.normal(0, 2))
        
        # 模拟显存使用（要最小化）
        memory_usage = model_size * batch_size * 0.1
        memory_usage = max(1, memory_usage + np.random.normal(0, 0.5))
        
        return {
            'accuracy': accuracy,
            'inference_speed': inference_speed,
            'memory_usage': memory_usage
        }
    
    def generate_search_space():
        """生成搜索空间"""
        return {
            'learning_rate': np.random.uniform(1e-6, 1e-3),
            'batch_size': np.random.choice([4, 8, 16, 32]),
            'model_size': np.random.choice([1, 3, 7, 13])  # 模型大小（B参数）
        }
    
    # 创建多目标优化器
    optimizer = MultiObjectiveOptimizer(
        objectives=['accuracy', 'inference_speed', 'memory_usage'],
        directions=['maximize', 'maximize', 'minimize']
    )
    
    # 执行优化
    print("开始多目标优化...")
    pareto_front = optimizer.optimize_multi_objective(
        multi_objective_function, 
        generate_search_space, 
        n_trials=200
    )
    
    print(f"\n帕累托前沿包含 {len(pareto_front)} 个解")
    
    # 显示帕累托前沿的解
    print("\n帕累托前沿解:")
    for i, solution in enumerate(pareto_front[:5]):  # 只显示前5个
        params = solution['params']
        scores = solution['scores']
        print(f"解 {i+1}:")
        print(f"  参数: LR={params['learning_rate']:.2e}, "
              f"Batch={params['batch_size']}, Model={params['model_size']}B")
        print(f"  目标: 准确率={scores['accuracy']:.3f}, "
              f"推理速度={scores['inference_speed']:.1f}, "
              f"显存={scores['memory_usage']:.1f}GB")
        print()
    
    # 绘制帕累托前沿
    optimizer.plot_pareto_front(0, 2)  # 准确率 vs 显存使用
    
    # 获取最佳折中解
    best_compromise = optimizer.get_best_compromise_solution({
        'accuracy': 0.5,
        'inference_speed': 0.3,
        'memory_usage': 0.2
    })
    
    if best_compromise:
        print("最佳折中解:")
        print(f"  参数: {best_compromise['params']}")
        print(f"  目标: {best_compromise['scores']}")
    
    return optimizer

# 运行多目标优化演示
print("\n=== 多目标优化演示 ===")
multi_obj_optimizer = demonstrate_multi_objective_optimization()
```

### 6.3 超参数调优的实用建议

**阶段性调优策略**：
1. **粗调阶段**：使用较大的搜索范围，快速确定参数的大致区间
2. **精调阶段**：在粗调结果的基础上，缩小搜索范围进行精细调优
3. **验证阶段**：在多个随机种子下验证最佳参数的稳定性

**资源分配策略**：
- 将80%的计算资源用于搜索学习率和批次大小
- 将15%的资源用于调优训练轮数和正则化参数
- 将5%的资源用于其他细节参数

**经验性规则**：
- 学习率通常是最重要的超参数，优先调优
- 批次大小的选择要考虑显存限制和梯度累积
- 训练轮数要结合早停策略，避免过拟合
- 不同任务类型有不同的参数敏感性

通过系统的超参数调优，结合自动化搜索技术和多目标优化方法，我们可以在有限的计算资源下找到最适合特定任务的参数配置。关键是要理解每个参数的作用机制，合理分配调优资源，并建立有效的实验管理流程。