# 3. 微调 vs 预训练

## 3.1 本质区别：站在巨人肩膀 vs 从零开始

微调和预训练代表了模型训练的两个不同阶段，它们的本质区别在于起点和目标。**预训练是从零开始构建通用知识体系**，模型在海量无标注数据上学习语言的基本规律、世界知识、常识推理等通用能力。这个过程就像是让一个人接受基础教育，学习语言、数学、科学等基础知识。

**微调是在已有知识体系上进行专项优化**，模型在特定任务的标注数据上学习任务特定的知识和技能。这个过程就像是让一个受过基础教育的人接受专业培训，学习特定领域的专业知识。

这种本质区别带来了一系列差异。预训练需要海量数据（通常TB级别）、大量计算资源（数千GPU）、长时间训练（数周到数月），但只需要做一次，训练出的模型可以服务于多种任务。微调需要少量数据（通常GB级别或更少）、较少计算资源（数个到数十个GPU）、较短时间（数小时到数天），但需要针对每个任务单独进行。

## 3.2 数据和资源需求的巨大差异

**预训练的数据需求**是惊人的。以GPT-3为例，它在45TB的文本数据上进行训练，包含了互联网上的大量网页、书籍、文章等。这些数据覆盖了人类知识的方方面面，使得模型能够学习到广泛的知识和能力。预训练数据通常是无标注的，需要原始文本即可，但需要经过严格的清洗和过滤。

**微调的数据需求**则要小得多。通常几千到几万条标注数据就足够了。这些数据是任务特定的，需要人工标注，质量要求很高。例如，训练一个医疗问答系统，可能需要5000-10000条医疗领域的问答对，每条都需要医学专家审核。

**预训练的计算资源需求**同样惊人。GPT-3的训练使用了数千块V100 GPU，训练时间长达数周。总计算量约为3.14×10²³ FLOPS，成本估计在数百万到数千万美元。这种规模的训练只有少数大公司和研究机构能够承担。

**微调的计算资源需求**则平易近人得多。使用LoRA或QLoRA等参数高效方法，在单张消费级GPU（如RTX 3090）上就可以微调7B规模的模型。训练时间通常在几小时到一天之内，成本可能只有几十到几百美元。

让我们通过一个对比表格来直观理解这些差异：

| 维度 | 预训练 | 微调 |
|------|--------|------|
| 数据量 | TB级（数万亿tokens） | GB级或更少（数百万tokens） |
| 数据类型 | 无标注文本 | 标注的任务数据 |
| 计算资源 | 数千GPU | 数个到数十个GPU |
| 训练时间 | 数周到数月 | 数小时到数天 |
| 成本 | 数百万到数千万美元 | 数十到数千美元 |
| 学习目标 | 通用语言理解 | 特定任务能力 |
| 训练频率 | 一次性（或很少更新） | 针对每个任务 |

## 3.3 训练目标和方法的差异

**预训练的训练目标**是学习通用的语言表示。对于因果语言模型（如GPT），目标是预测下一个词；对于掩码语言模型（如BERT），目标是预测被遮盖的词。这些目标看似简单，但要在海量数据上做好，模型需要学习语法、语义、常识、推理等多方面的能力。

```python
# 预训练的简化示例（实际实现要复杂得多）
def pretrain_step(model, text_batch):
    """
    预训练的一个训练步骤
    目标：预测下一个词
    """
    # 将文本转换为token序列
    tokens = tokenizer(text_batch)
    
    # 输入是前n-1个token，目标是后n-1个token
    inputs = tokens[:, :-1]
    targets = tokens[:, 1:]
    
    # 前向传播
    logits = model(inputs)
    
    # 计算损失：预测每个位置的下一个词
    loss = cross_entropy_loss(logits, targets)
    
    return loss

# 预训练循环（极度简化）
for epoch in range(num_epochs):
    for batch in massive_text_corpus:  # 海量文本数据
        loss = pretrain_step(model, batch)
        loss.backward()
        optimizer.step()
```

**微调的训练目标**是学习任务特定的能力。目标函数根据任务类型而定：分类任务使用交叉熵损失，生成任务使用语言模型损失，问答任务可能使用span预测损失等。

```python
# 微调的示例
def finetune_step(model, task_batch):
    """
    微调的一个训练步骤
    目标：完成特定任务
    """
    inputs, labels = task_batch
    
    # 前向传播
    outputs = model(inputs)
    
    # 计算任务特定的损失
    if task_type == "classification":
        loss = cross_entropy_loss(outputs, labels)
    elif task_type == "generation":
        loss = language_model_loss(outputs, labels)
    elif task_type == "qa":
        loss = span_prediction_loss(outputs, labels)
    
    return loss

# 微调循环
for epoch in range(num_epochs):  # 通常3-5个epoch
    for batch in task_specific_data:  # 任务特定数据
        loss = finetune_step(model, batch)
        loss.backward()
        optimizer.step()
```

## 3.4 何时需要预训练？

在大多数情况下，我们不需要从零开始预训练模型，因为已经有很多优秀的开源预训练模型可用（如LLaMA、Mistral、Qwen等）。但在某些特殊情况下，预训练可能是必要的：

**第一，当你有独特的数据源时**。如果你拥有大量的、其他模型没有见过的数据（如特定公司的内部文档、特定语言的文本、特定领域的专业资料），预训练可以让模型充分利用这些数据。

**第二，当你需要特定的模型架构时**。如果现有的预训练模型架构不适合你的需求（如需要特殊的注意力机制、特殊的位置编码等），你可能需要自己预训练。

**第三，当你需要完全的控制和定制时**。预训练让你可以完全控制训练数据、训练过程、模型行为等，这在某些对安全性、可控性要求极高的场景中很重要。

**第四，当你有充足的资源时**。如果你是大公司或研究机构，有足够的计算资源和数据，预训练可以让你拥有自己的基础模型，不依赖于他人。

但对于绝大多数应用场景，**使用现有的预训练模型进行微调是更明智的选择**。这样可以：
- 节省大量的时间和成本
- 利用已经学到的通用知识
- 专注于任务特定的优化
- 更快地迭代和部署

## 3.5 持续预训练：介于预训练和微调之间

有一种方法介于预训练和微调之间，叫做**持续预训练（Continual Pre-training）**或**领域自适应预训练（Domain-Adaptive Pre-training）**。这种方法在预训练模型的基础上，使用领域特定的无标注数据继续进行预训练，然后再进行任务微调。

持续预训练的典型流程是：

```python
# 第一步：加载预训练模型
base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")

# 第二步：在领域数据上持续预训练
domain_corpus = load_domain_corpus()  # 如医疗领域的大量文本

# 使用语言模型目标继续训练
for epoch in range(num_epochs):  # 通常1-3个epoch
    for batch in domain_corpus:
        # 预测下一个词（与预训练相同的目标）
        loss = language_model_loss(base_model, batch)
        loss.backward()
        optimizer.step()

# 保存领域适应后的模型
base_model.save_pretrained("./domain_adapted_model")

# 第三步：在任务数据上微调
task_data = load_task_data()  # 如医疗问答数据

for epoch in range(num_epochs):
    for batch in task_data:
        loss = task_specific_loss(base_model, batch)
        loss.backward()
        optimizer.step()

# 保存最终模型
base_model.save_pretrained("./final_model")
```

持续预训练的优势是：
- 让模型学习领域特定的词汇和知识
- 改善模型在领域任务上的表现
- 数据需求介于预训练和微调之间（需要大量无标注领域数据）

持续预训练特别适合以下场景：
- 你有大量的领域无标注数据（如医疗文献、法律文书）
- 领域与通用语料差异较大（如专业术语多、表达方式特殊）
- 你需要在该领域的多个任务上应用模型

## 3.6 实战案例：医疗领域模型的构建

让我们通过一个完整的案例来理解预训练、持续预训练和微调的关系：

**场景**：构建一个医疗问答系统

**方案一：直接微调通用模型**

```python
# 加载通用预训练模型
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")

# 直接在医疗问答数据上微调
medical_qa_data = load_medical_qa_data()  # 5000条医疗问答

trainer = Trainer(
    model=model,
    train_dataset=medical_qa_data,
    args=TrainingArguments(
        num_train_epochs=3,
        learning_rate=2e-5
    )
)

trainer.train()

# 评估
test_accuracy = evaluate(model, test_data)
print(f"Test accuracy: {test_accuracy}")  # 假设得到75%
```

**方案二：持续预训练 + 微调**

```python
# 第一步：在医疗文献上持续预训练
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")

medical_corpus = load_medical_corpus()  # 10GB医疗文献

# 持续预训练
for epoch in range(2):
    for batch in medical_corpus:
        loss = language_model_loss(model, batch)
        loss.backward()
        optimizer.step()

model.save_pretrained("./medical_pretrained_model")

# 第二步：在医疗问答数据上微调
medical_qa_data = load_medical_qa_data()

trainer = Trainer(
    model=model,
    train_dataset=medical_qa_data,
    args=TrainingArguments(
        num_train_epochs=3,
        learning_rate=2e-5
    )
)

trainer.train()

# 评估
test_accuracy = evaluate(model, test_data)
print(f"Test accuracy: {test_accuracy}")  # 假设得到82%
```

**结果对比**：
- 方案一（直接微调）：准确率75%，训练时间2小时
- 方案二（持续预训练+微调）：准确率82%，训练时间10小时

方案二虽然时间更长，但效果显著更好。这是因为持续预训练让模型学习了大量的医疗知识和术语，为后续的任务微调打下了更好的基础。

**何时选择持续预训练？**
- 当你有大量领域无标注数据时（如10GB以上）
- 当领域与通用语料差异较大时
- 当你需要在该领域的多个任务上应用时
- 当你有足够的计算资源和时间时

**何时直接微调？**
- 当你的领域数据有限时
- 当时间和资源紧张时
- 当任务相对简单时
- 当领域与通用语料差异不大时
