
## 5. 综合决策框架

在理解了微调与其他优化方案的区别后，我们需要一个综合的决策框架来指导实际选择。

### 5.1 决策维度

选择优化方案时，需要考虑以下维度：

**1. 任务需求**
- 性能要求：需要达到什么准确率？
- 任务复杂度：是简单分类还是复杂推理？
- 领域特殊性：是通用任务还是专业领域？

**2. 数据情况**
- 标注数据量：有多少标注数据？
- 无标注数据量：有多少领域数据？
- 数据质量：标注准确性如何？

**3. 资源约束**
- 计算资源：有什么GPU？有多少？
- 时间约束：多久需要出结果？
- 预算限制：能投入多少成本？

**4. 部署环境**
- 部署位置：云端还是边缘设备？
- 延迟要求：实时还是离线？
- 资源限制：部署环境的资源如何？

**5. 维护需求**
- 更新频率：需要多久更新一次？
- 任务数量：需要支持多少个任务？
- 长期规划：是短期项目还是长期产品？

### 5.2 决策流程图

```
开始
  ↓
是否有GPU资源？
  ├─ 否 → 使用Prompt Engineering或API服务
  └─ 是 → 继续
       ↓
标注数据量？
  ├─ <100条 → Prompt Engineering (Few-shot)
  ├─ 100-500条 → 微调（LoRA，小rank）
  ├─ 500-5000条 → 微调（LoRA或Adapter）
  └─ >5000条 → 继续
       ↓
是否有大量领域无标注数据？
  ├─ 是 → 持续预训练 + 微调
  └─ 否 → 直接微调
       ↓
部署环境资源如何？
  ├─ 受限 → 微调 + 蒸馏
  └─ 充足 → 直接部署微调模型
       ↓
结束
```

### 5.3 实用决策工具

```python
class OptimizationStrategySelector:
    """优化策略选择器"""
    
    def __init__(self):
        self.strategies = {
            "prompt_engineering": {
                "cost": "极低",
                "time": "即时",
                "performance": "中等",
                "stability": "低",
                "适用场景": "快速原型、简单任务、数据极少"
            },
            "finetuning": {
                "cost": "中等",
                "time": "小时到天",
                "performance": "高",
                "stability": "高",
                "适用场景": "有标注数据、需要稳定性能"
            },
            "continual_pretraining": {
                "cost": "较高",
                "time": "天到周",
                "performance": "很高",
                "stability": "很高",
                "适用场景": "有大量领域数据、多任务应用"
            },
            "distillation": {
                "cost": "中等",
                "time": "小时到天",
                "performance": "中高",
                "stability": "高",
                "适用场景": "需要部署到资源受限环境"
            },
            "finetuning_plus_distillation": {
                "cost": "较高",
                "time": "天",
                "performance": "高",
                "stability": "高",
                "适用场景": "需要高性能和高效率"
            }
        }
    
    def select(self, 
               labeled_data_size: int,
               unlabeled_data_size: int,
               has_gpu: bool,
               gpu_memory_gb: float,
               time_constraint: str,
               performance_requirement: str,
               deployment_environment: str):
        """
        选择最佳优化策略
        
        Returns:
            推荐策略和详细说明
        """
        
        recommendations = []
        
        # 规则1：没有GPU或时间极度紧张
        if not has_gpu or time_constraint == "urgent":
            recommendations.append({
                "strategy": "prompt_engineering",
                "priority": "高",
                "reason": "资源或时间限制，只能使用Prompt Engineering"
            })
            return recommendations
        
        # 规则2：数据量很少
        if labeled_data_size < 100:
            recommendations.append({
                "strategy": "prompt_engineering",
                "priority": "高",
                "reason": "标注数据太少，微调容易过拟合"
            })
            if labeled_data_size >= 10:
                recommendations[-1]["note"] = "可以使用Few-shot Learning"
            return recommendations
        
        # 规则3：有中等数量标注数据
        if 100 <= labeled_data_size < 5000:
            recommendations.append({
                "strategy": "finetuning",
                "method": "LoRA" if gpu_memory_gb < 24 else "LoRA或全量微调",
                "priority": "高",
                "reason": f"有{labeled_data_size}条标注数据，适合微调"
            })
        
        # 规则4：有大量标注数据和领域数据
        if labeled_data_size >= 5000 and unlabeled_data_size >= 10000:
            recommendations.append({
                "strategy": "continual_pretraining",
                "priority": "中",
                "reason": "有大量领域数据，持续预训练可以进一步提升效果"
            })
        
        # 规则5：部署环境受限
        if deployment_environment in ["edge", "mobile"]:
            if labeled_data_size >= 500:
                recommendations.append({
                    "strategy": "finetuning_plus_distillation",
                    "priority": "高",
                    "reason": "部署环境资源受限，需要蒸馏"
                })
            else:
                recommendations.append({
                    "strategy": "distillation",
                    "priority": "中",
                    "reason": "部署环境受限，但数据不足以支持高质量微调"
                })
        
        # 规则6：高性能要求
        if performance_requirement == "best" and labeled_data_size >= 1000:
            recommendations.append({
                "strategy": "finetuning",
                "method": "全量微调或大rank的LoRA",
                "priority": "高",
                "reason": "追求最佳性能"
            })
        
        # 排序和返回
        recommendations.sort(key=lambda x: {"高": 0, "中": 1, "低": 2}[x["priority"]])
        
        return recommendations

# 使用示例
selector = OptimizationStrategySelector()

recommendations = selector.select(
    labeled_data_size=2000,
    unlabeled_data_size=50000,
    has_gpu=True,
    gpu_memory_gb=24,
    time_constraint="normal",
    performance_requirement="high",
    deployment_environment="cloud"
)

print("推荐的优化策略：")
for i, rec in enumerate(recommendations, 1):
    print(f"\n{i}. {rec['strategy']}")
    print(f"   优先级: {rec['priority']}")
    print(f"   理由: {rec['reason']}")
    if 'method' in rec:
        print(f"   具体方法: {rec['method']}")
    if 'note' in rec:
        print(f"   注意: {rec['note']}")
```

