# 2. ⚖️ 法律：构建LightLLM+LlamaIndex法律智能体


近年来，大语言模型（LLM）能力显著，但其知识的静态滞后性导致其在处理新信息或专业问题时易产生“幻觉”。RAG（retrieval-augmented generation，检索增强生成）框架通过“先检索后生成”的方式，将外部知识库的准确性与LLM的生成能力相结合，有效解决了这一问题，成为构建企业知识库、法律医疗等专业应用的核心技术。在此背景下，掌握以LightLLM为代表的高效推理框架，不仅能帮助学习者深入理解RAG的协同机制，更能培养在资源受限环境下优化与部署AI系统的关键能力，为投身AI应用开发奠定坚实基础。

## 2.1 前提条件
* 用户已经获取LLaMA-Factory Online平台账户和密码，如果需要帮助或尚未注册，可参考[注册账户](https://docs.llamafactory.online/docs/documents/quickstart/loginAccount)完成注册。
* 当前账号的余额充裕，可满足实例运行的需要。点击可了解[最新的活动](https://docs.llamafactory.online/docs/documents/quickstart/freetrialguide)，或前往[充值](https://apps.datacanvas.com/bill/recharge)，如需了解更多请[联系我们](https://docs.llamafactory.online/docs/documents/recharge/refill#发票)。




## 2.2 操作步骤
**配置概览**

| 配置参数 |  配置项    |  说明|
| --- |:----------|----| 
| 模型 |Qwen3-8B |本实践通过本地启动大模型服务 |
|GPU| H800*1  | -                    | |

**操作详情**


1. 使用已注册的LLaMA-Factory Online账号登录平台，选择[实例空间]菜单项，进入实例空间页面，例如下图所示。

![SwanLab对比图](https://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/roleplay/startWT.png)

2. 单击上图“开始微调”按钮，进入[配置资源]页面，选择GPU资源，卡数填写`1`，其他参数保持为默认值，单击“启动”按钮，启动实例。

![SwanLab对比图](http://s1.llamafactory.online/lmlab/docs/v1.0/paper/1.png) 

3. 实例启动后，可启动VSCode或者JupyterLab专属数据处理，本次实践我们使用VSCode专属数据处理，单击图标链接进入数据处理页面，点击[Terminal/New Terminal]进入终端页面。在终端运行如下所示的命令安装服务运行所需环境。
 
    1. 运行如下命令创建一个名称为“py39”的Python环境。
     ```shell
     conda create -n lightllm python=3.10
     ```
     2. 运行如下所示的命令激活自定义的环境。
     ```shell
     conda activate lightllm
     ```
     3. 运行如下所示的命令，在已经激活的Python环境中安装`ipykernel`包。
      ```shell
      pip install ipykernel -i https://pypi.tuna.tsinghua.edu.cn/simple
      ```
     4. 运行如下所示的命令，将当前Python环境注册为Jupyter内核。

      ```bash
      kernel_install --name lightllm  --display-name "Python 3.10 (lightllm)"
      ```
    > **提示**
    > 
    > 您需在对应的 Conda 环境中运行上述注册命令，否则内核（kernel）将无法正确注册。

4. Python环境安装完成后，在终端运行如下所示的命令下载并安装LightLLM框架及其依赖项，例如下图所示。

     1. 运行如下命令，从GitHub仓库克隆LightLLM项目的源代码到本地。
     ```shell
     git clone https://github.com/ModelTC/lightllm.git
     ```
     2. 运行如下所示的命令，进入项目目录。
     ```shell
     cd lightllm
     ```
     3. 运行如下所示的命令，安装项目运行所需的所有Python依赖包。
      ```shell
      pip install -r requirements.txt
      ```
     4. 运行如下所示的命令，以开发模式安装LightLLM包。
      ```shell
      python setup.py install
      ```
     5. 运行如下命令，安装LlamaIndex库，用于构建基于私有数据的检索增强生成（RAG）应用。
      ```shell
      pip install llama-index
      ```
     6. 运行如下所示的命令，安装Streamlit库，用于快速创建交互式数据可视化网页应用。
     ![SwanLab对比图](https://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/2.png)

     ```shell
     pip install streamlit
     ```
   
   
     7. 运行如下命令，安装LightLLM运行所需的计算机视觉处理库和WebSocket通信支持依赖包。
     ```shell
     pip install torchvision
     pip install websockets
     pip install partial-json-parser
     pip install interegular
     ```
     8. 运行如下命令，安装LlamaIndex框架对HuggingFace本地嵌入模型的支持包，使RAG应用能够使用BAAI/bge等本地嵌入模型进行文本向量化。
     ```shell
     pip install llama-index-embeddings-huggingface
     ```
    
       
    您可运行`pip list | grep -E "torchvision|websockets|partial-json-parser|interegular|streamlit|llama-index|llama-index-embeddings-huggingface"`命令查看依赖包安装情况，例如下图所示。
     
     ![SwanLab对比图](http://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/8.png)
    

5. 依赖包安装完成后，运行如下所示命令，启动LightLLM框架的API服务器提供标准的OpenAI兼容接口，支持文本生成、对话等推理功能，模型加载成功后，页面显示例如下图所示，默认端口为8000。
   
   ![SwanLab对比图](http://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/lanunchser.png)

      ```shell
      python -m lightllm.server.api_server --model_dir /shared-only/models/Qwen/Qwen3-8B
      ```

  
    
6. 新建Terminal窗口，执行如下代码测试模型推理功能是否正常，服务正常启动页面例如下图所示。

    ![SwanLab对比图](http://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/result.png)
        ```json
        curl -X POST "http://localhost:8000/v1/chat/completions" \
          -H "Content-Type: application/json" \
          -d '{
            "model": "Qwen3-8B",
            "messages": [{"role": "user", "content": "Hello"}],
            "max_tokens": 1000
          }'
        ```

7. 点击链接[下载app.py](http://llamafactory-online-assets.oss-cn-beijing.aliyuncs.com/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/app.py)，下载后将文件拖拽至`/workspace/lightllm`目录下，然后运行如下所示命令加载RAG服务，加载成功后页面例如下图所示。

    ![SwanLab对比图](http://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/3.png)

      ```shell
      streamlit run app.py \
          --server.address 0.0.0.0 \
          --server.port 6666 \
          --server.enableCORS false \
          --server.enableXsrfProtection false
      ```

8. 点击服务链接，进入本地RAG文档搜索助手页面，例如下图所示。

    ![SwanLab对比图](http://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/44.png)

## 2.3 服务应用
服务部署完成后，用户可自定义构建知识库，并基于库内信息查询相关问题，快速获取解决方案。


单击上方高亮区域的“Browse files”按钮，选择PDF或TXT格式的知识库文件上传，或直接将文件拖拽至该区域，本实践上传[示例1](http://llamafactory-online-assets.oss-cn-beijing.aliyuncs.com/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/%E5%8A%B3%E5%8A%A8%E6%B3%95%E6%9D%A1%E4%BE%8B1.txt)，[示例2](http://llamafactory-online-assets.oss-cn-beijing.aliyuncs.com/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/%E5%8A%B3%E5%8A%A8%E6%B3%95%E6%9D%A1%E4%BE%8B2.txt)。

待页面出现“✅文档已加载并索引！”即可输入您的问题，例如：“ 我有考勤记录截图和与领导沟通加班的微信记录。劳动合同写的是月薪8000元，但公司一直按基本工资3000元为基数算加班费。我主张最近一年的。”。观察应用回复，例如下图所示，回答详情可展开“Details”查看详情。

![SwanLab对比图](http://s1.llamafactory.online/llamafactory-online/docs/v2.0/documents/Practice/lightLLMagent/5.png)




<details>
<summary>回答</summary>

&lt;think&gt;

好的，用户上个月离职了，但公司还欠他很多加班费没给，他不知道该怎么办。首先，我需要根据提供的上下文信息来给出建议。用户之前已经有一些相关的提问和回答，比如关于加班费计算基数、仲裁申请书的撰写以及电子签字的补强方法。现在的情况是用户已经离职，但仍有未支付的加班费。

首先，用户需要确认自己是否已经收集了足够的证据。根据之前的对话，用户有加班考勤记录、工资条和劳动合同。这些证据是关键，因为仲裁需要这些来支持主张。用户可能还需要检查是否有其他证据，比如微信聊天记录、邮件或者工作群里的消息，这些可以证明加班的事实和公司的安排。

接下来，用户需要考虑是否已经超过了仲裁时效。根据中国的劳动法，劳动争议的仲裁时效是一年，从知道或应当知道权利被侵害之日起计算。用户上个月离职，如果加班费是在离职前发生的，那么时效可能还未超过。但需要确认具体的时间点，比如最后加班的时间和离职时间之间的关系。

然后，用户应该准备仲裁申请。根据之前的建议，需要整理好证据，包括考勒记录、工资条、劳动合同等，并计算加班费的差额。用户可能需要计算按照劳动合同约定的工资基数计算的加班费，与公司实际支付的差额，并准备具体的金额。同时，用户需要撰写仲裁申请书，明确请求支付的金额和理由。

另外，用户提到之前有电子审批单的问题，但现在已经离职，可能需要确保电子证据的合法性。比如，如果电子签字被质疑，用户需要准备系统登录方式或关联的微信记录来补强证据。不过，现在可能已经没有机会在庭上展示，所以需要提前准备好这些材料，以防仲裁员提出质疑。

用户可能还需要考虑是否需要律师的帮助，尤其是如果公司有较强的法律团队，或者案件复杂的情况下。但根据之前的建议，用户可以自行准备材料，因为证据充分的话，法律优势明显。

最后，用户需要按照仲裁程序提交申请，确保在规定的时效内，并且正确填写所有必要的文件。如果仲裁结果不满意，还可以考虑诉讼，但诉讼的时效是两年，需要留意时间节点。

总结下来，用户需要做的步骤包括:确认证据完整性，计算加班费差额，准备仲裁申请材料，确保时效性，并可能寻求法律援助。同时，注意不要遗漏任何可能的证据，如电子记录的合法性，以及离职后是否还有追诉权。

&lt;think&gt;

你的考勤记录截图和微信沟通记录已能形成完整证据链，可明确主张以实际月工资 8000 元为基数计算加班费。具体操作建议如下：

你已离职但仍有加班费未支付，可按以下步骤维权:

1. **确认证据完整性**：整理所有加班记录(考勤截图、工资条、劳动合同、微信/邮件沟通记录等)，确保能证明加班事实及公司未足额支付。

2. **计算加班费差额**：以劳动合同约定的工资为基数(如月薪7000元)，按法定标准(工作日1.5倍、周末2倍、节假日3倍)计算应得加班费，核对已支付金额，明确差额。

3. **申请劳动仲裁**：在离职后1年内向公司所在地劳动仲裁委员会提交申请，明确请求支付欠付的加班费差额。需准备证据清单及仲裁申请书，说明事实与理由。

4. **应对电子证据质疑**：若存在电子审批单等电子证据，可提前准备系统操作记录或关联聊天记录(如领导微信确认加班内容)，证明其真实性。

5. **时效与后续程序**：劳动仲裁时效为1年，离职后仍可主张。若仲裁结果不满意，可在15日内向法院提起诉讼。

建议尽快行动，避免超过时效，同时保持证据链完整以提高胜诉率。
</details>





多维度对比两类服务的回复，对比详情如下所示。

| 对比维度 | RAG服务回复 |原生模型回复 |
|---------|------------------|--------------------|
| **1. 计算基数主张** | ✅ 明确指出应以实际发放工资8000元为基数，并提出反驳策略：“工资条未列明加班费项目”、“银行流水为证” | ⚠️ 仅说明“可能存在违法风险”，未给出具体举证方式或反制话术 |
| **2. 证据链构建** | ✅ 强调“考勤截图+微信记录”需相互印证，并建议“当庭登录系统验证真实性”——这是关键实操技巧 | ❌ 仅说“需能证明具体时间”，缺乏操作指引 |
| **3. 加班事实认定** | ✅ 点出核心：“加班系公司安排而非自愿”——这是仲裁胜负关键点之一 | ❌ 未涉及此关键法律要件 |
| **4. 差额计算方法** | ✅ 明确列出倍数标准（工作日1.5倍、周末2倍、法定节假日3倍），要求精确核算差额金额 | ❌ 只提法律规定，无具体计算指导 |
| **5. 应对公司抗辩** | ✅ 预判对方可能说“3000是基本工资”，并提供标准反驳话术：“劳动合同未约定工资构成”、“公司未提供薪酬制度证明”，应视为未足额支付 | ❌ 虽提到地方差异，但未教用户如何应对企业常见推诿 |
| **6. 仲裁请求撰写** | ✅ 明确写出应提交的仲裁请求模板，包括诉求金额、法律依据（《劳动法》第44条、《工资支付暂行规定》第13条） | ❌ 仅有知识介绍，无行动指令 |
| **7. 用户角色定位** | ✅ 把用户当作即将出庭的申请人，给予战斗性、可执行的诉讼策略指导 | ❌ 把用户当作学习者，进行普法教育式的内容输出 |

RAG服务回复更具实战性、对抗性和可操作性，适合作为智能法律助手的输出标准，把用户当作即将出庭的申请人，给予战斗性、可执行的诉讼策略指导。




## 2.4 总结
通过“轻量级RAG验证 → 功能迭代优化 → 企业级部署落地”的渐进式路径，我们基于LightLLM高效推理引擎，构建了一套可落地的智能知识服务系统。该方案有效缓解了大模型在专业领域存在的知识滞后与幻觉问题，可在法律场景中实现从法条检索、判例匹配到案情分析的全流程应用，显著提升响应准确率与业务可用性。

实践验证了该架构在高精度、强合规性场景下的可行性，具备向金融、医疗、政务等知识密集型行业快速复制的能力。后续将持续深化多模态内容理解、复杂任务编排与安全可控机制，推动RAG技术与企业业务流程深度融合，打造稳定、可解释、可扩展的行业AI解决方案，真正实现人工智能在核心业务场景中的价值闭环。
