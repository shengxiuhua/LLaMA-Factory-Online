# 前言

2022年底，ChatGPT的问世让人工智能从实验室走进了千家万户，也标志着大语言模型（Large Language Model，LLM）时代的全面到来。从那时起，LLM不再只是科研人员关注的前沿技术，而是开始真正改变人们工作、学习和生活的方式。

LLM是自然语言处理（Natural Language Processing，NLP）领域长期技术积累的结晶。在LLM出现之前，NLP经历了从符号主义到统计学习，再到深度学习和预训练模型的多次演进。以GPT、BERT为代表的预训练语言模型（Pretrain Language Model，PLM）曾是上一代的技术高峰，它们通过在海量文本上进行预训练，获得了理解自然语言的基本能力。但这些模型在实际应用中仍然存在局限：需要针对具体任务进行复杂的微调，在内容生成方面表现不稳定，更重要的是，它们与人们期待的"真正懂你"的智能助手还有不小的距离。

LLM的突破在于，它不仅大幅扩展了模型规模和训练数据量，更重要的是引入了指令理解、人类反馈学习等创新机制。这使得LLM具备了"涌现能力"——它能通过少量示例快速理解新任务，能准确把握用户意图并给出高质量回复，甚至能在复杂场景下进行推理和创造。这些能力让LLM第一次真正具备了作为通用智能助手的潜力。

正因如此，全球范围内掀起了LLM研发和应用的热潮。从最初的ChatGPT，到更强大的GPT-4，再到专注推理的DeepSeek-R1、支持图文理解的Qwen-VL等各具特色的模型，LLM技术在短短两年内实现了飞速迭代。与此同时，基于LLM的各类应用也如雨后春笋般涌现，从智能客服到内容创作，从代码助手到数据分析，LLM正在各行各业展现出巨大的应用价值。可以预见，在不久的将来，LLM将成为数字社会的基础设施，深度融入每个人的日常。

在这样的背景下，我们团队陆续推出了"LLaMA-Factory-Online"和"Lab4AI"（大模型试验室）两个大模型应用平台，前者通过集成化工具链、可视化操作界面与自动化工作流，助力用户快速实现模型从开发调试到生产部署的全周期闭环；后者聚焦于高算力需求的应用场景，构建了开放共享的内容社区生态。这两个项目得到了国内外众多开发者的认可和支持，但我们也从用户反馈中发现，市场上仍然缺少一份既讲清楚原理、又注重实战的完整教程。

因此，我们编写了这本结合理论与实践的LLM产品手册。本手册从NLP的基础概念出发，沿着LLM的演进脉络层层深入，为读者系统讲解LLM的核心架构和训练方法。更重要的是，该手册会结合业界主流的开发框架，手把手带你搭建和训练一个真正可用的LLM。我们的目标不仅是告诉你"是什么"，更要让你学会"怎么做"。

## 写给用户的建议

本手册涵盖大模型微调的理论基础、技术原理和实战案例，通过原理剖析、参数配置和代码实现，帮助你全面掌握大模型微调的核心知识和应用能力。因此，本手册适合大模型平台用户、产品经理、技术开发者以及希望将大模型应用于实际业务场景的企业用户阅读。

在阅读本手册之前，你最好具备基本的编程能力（尤其是Python），对机器学习有初步了解，并对自然语言处理的基本概念有所认知，这会帮助你更顺利地理解手册内容。如果你是零基础读者，我们建议你先通过在线课程或入门书籍补充相关知识。

本手册分为基础篇和实战篇。**基础篇**（第1-4章）从浅入深介绍大模型原理：第1章梳理自然语言处理的基本任务和发展历程，帮助非专业读者建立全局认知；第2章详解Transformer架构，这是理解现代大模型的关键基础；第3章介绍经典预训练语言模型的核心思想，并对比分析主流模型的设计理念；第4章正式进入大语言模型主题，系统讲解大模型的核心能力和技术特点。**实战篇**（第5-10章）则带你深入大模型微调的技术细节：第5章全面介绍大模型微调的方法和技术路线；第6章对比微调与其他模型优化方案的差异和适用场景；第7章介绍主流微调框架和工具栈的使用方法；第8章详解数据集构建与处理的最佳实践；第9章深入分析微调参数的配置策略；第10章总结微调项目的最佳实践和经验技巧。你可以根据自己的兴趣和需求选择性阅读。

大模型微调是一个快速演进、高度实践的领域，光看理论远远不够。请务必动手运行手册中的代码，尝试修改参数、复现实验，有条件的话可以在实际业务场景中应用微调技术，在实战中真正掌握大模型微调能力。遇到问题时，欢迎在Datawhale社区或其他开源社区提问交流。Datawhale会持续跟踪AI前沿技术，也欢迎你关注或参与社区共建。