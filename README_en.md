# LLM-Cookbook 


<div align='center'>
    <img src="/docs/images/2.jpg" alt="alt text" width="100%"> 
    <h1>LLM-Cookbook</h1>
</div>

<div align="center">
  <img src="https://img.shields.io/github/stars/LLaMAFactoryOnline/LLaMA-Factory-Online?style=flat&logo=github" alt="GitHub stars"/>
  <img src="https://img.shields.io/github/forks/LLaMAFactoryOnline/LLaMA-Factory-Online?style=flat&logo=github" alt="GitHub forks"/>
  <img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language"/>
  <a href="https://github.com/LLaMAFactoryOnline/LLaMA-Factory-Online"><img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&logo=github" alt="GitHub Project"></a>

</div>



<div align="center">

[English](./README.md) 

</div>

<div align="center">

  <h3>ğŸ“š Hands-On LLM Fine-Tuning Tutorial from Scratch</h3>
  <p><em>Master core LLM fine-tuning techniques from the ground up with step-by-step guidance to professional-grade model customization (Powered by LlamaFactory Online)</em></p>
</div>

---



## ğŸ¯ Project Overview

As large language models evolve rapidly, more developers seek to integrate their domain expertise and vertical industry data with these models. However, they often find themselves overwhelmed by massive parameter counts, complex training pipelines, and diverse fine-tuning techniques. To address this, we present theÂ LLM-CookbookÂ projectâ€”a comprehensive, practical guide to fine-tuning large language models.

This project delivers a systematic tutorial specifically designed for LLM fine-tuning, spanning from foundational concepts to advanced techniques, and from theoretical principles to hands-on implementation. We guide you through the core mechanisms of various fine-tuning methods, equip you with practical skills in data processing, hyperparameter optimization, and model evaluation, and demonstrate real-world industry applications for deploying LLMs in production scenarios. Our goal is to make this guide an essential resource for every developer aspiring to master customized large language model capabilities.



## âœ¨ What You will Gain

ğŸ¯ **Deep Theoretical Mastery**
- Comprehensive understanding of core principles and technological evolution in LLM fine-tuning
- Mastery of efficient fine-tuning mechanisms including LoRA, Adapter, and Prefix Tuning
- Insight into selecting appropriate fine-tuning strategies for different scenarios

ğŸ› ï¸ **Comprehensive Practical Skills**
- End-to-end proficiency in data processing, model training, and evaluation optimization
- Performance optimization techniques for fine-tuning across diverse hardware configurations
- Engineering methodologies for model deployment, monitoring, and iteration

ğŸ¢ **Industry-Specific Expertise**
- Hands-on experience with fine-tuning cases in healthcare, legal, finance, manufacturing, and other verticals
- Professional knowledge in regulatory compliance, data security, and effectiveness evaluation
- Complete enterprise-grade LLM application solutions

ğŸŒ **Active Open-Source Engagement**
- Access to a vibrant open-source community for in-depth exchanges with industry experts
- Complimentary cloud-based compute resources for fine-tuning
- Opportunities to contribute and become a core project maintainer

## ğŸ“– Content Navigation


# ğŸ“š LLM Fine-Tuning Learning Roadmap

| Chapter | Title                          | Core Content              | Status |
|----------|-----------------------------------|--------------------------------|------|
| Chapter 1  | [NLP Fundamentals](./docs/chapter1/1.%20NLPæ˜¯ä»€ä¹ˆ.md)  | Covers foundational NLP concepts, technological evolution, and core tasks.| âœ…    |
| Chapter 2  | [Transformer Architecture](./docs/chapter2/1.%20Transformerçš„å†å²æ„ä¹‰ä¸æŠ€æœ¯é©å‘½.md)| Analyzes attention mechanisms and builds complete Transformer models.| âœ…    |
| Chapter 3   | [Pre-trained Language Models](./docs/chapter3/1.%20é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„é©å‘½æ€§æ„ä¹‰.md) | Introduces three categories of pre-trained language model architectures with selection guidelines.| âœ…    |
| Chapter 4   | 	[Large Language Model](./docs/chapter4/1.%20å¤§è¯­è¨€æ¨¡å‹çš„æ—¶ä»£æ„ä¹‰.md)  | Explores LLM definitions and training methodologies.| âœ…    |
| Chapter 5   | [LLM Fine-Tuning](./docs/chapter5/1.%20å¤§æ¨¡å‹å¾®è°ƒçš„å¿…è¦æ€§ä¸ä»·å€¼.md)  | Explains mainstream fine-tuning techniques including SFT and LoRA, with practical guides and pitfall avoidance strategies.| âœ…  |
| Chapter 6   | [Fine-Tuning vs. Other Model Optimization Approaches](./docs/chapter6/1.%20ç†è§£æ¨¡å‹ä¼˜åŒ–çš„å…¨æ™¯å›¾.md)     | Compares fine-tuning with prompt engineering, distillation, and pre-training, providing decision-making frameworks.| âœ…   |
| Chapter 7   | [Mainstream Fine-Tuning Frameworks & Toolchains](./docs/chapter7/1.%20æ„å»ºé«˜æ•ˆå¾®è°ƒç”Ÿæ€ç³»ç»Ÿ.md)       | Introduces fine-tuning tools like PEFT, along with data processing and hardware optimization solutions.| âœ…    |
| Chapter 8   | [Dataset Construction & Processing](./docs/chapter8/1.%20æ•°æ®è´¨é‡å†³å®šæ¨¡å‹ä¸Šé™.md) | Covers dataset construction principles and preprocessing workflows.| âœ…    |
| Chapter 9   | [Fine-Tuning Hyperparameters Explained](./docs/chapter9/1.%20è¶…å‚æ•°çš„è‰ºæœ¯ä¸ç§‘å­¦.md)  | Analyzes tuning techniques for hyperparameters such as learning rate and batch size, with quick reference tables.| âœ…    |
| Chapter 10   | [LlamaFactory Online](./docs/chapter10/äº§å“ç®€ä»‹.md)| Guides through cloud-based fine-tuning platform registration, usage, and free trial access.| âœ…    |
| Chapter 11 | [Best Practice](./docs/chapter11/æœ€ä½³å®è·µ.md) | Showcases real-world LLM fine-tuning implementations in healthcare, legal, and finance domains.| ğŸ› ï¸    |

---


## ğŸ¯ Models


## Curated Latest Model Collection

The platform features an extensive library of AI models. Users can simply click [Model List](./Extra-Chapter/modelList.md) to view and access all available models without manual searching. Below are representative examples of the platformâ€™s latest releases: Qwen3, InternVL3, Qwen3-VL, and more. These models commonly incorporate cutting-edge technical capabilities including:  
- **Chain-of-Thoughtï¼ˆCoTï¼‰Reasoning**  
- **Mixture of Expertsï¼ˆMoEï¼‰architecture**  
- **Reinforcement Learningï¼ˆRLï¼‰â€”based optimization**
- **Enhanced multimodal understanding, video analysis, and complex reasoning** to meet diverse application requirements


| Model Name | Domain | Download Path | Publisher | Key Features |
|---------|---------|---------|-----------|---------|
| Qwen3-4B-Instruct-2507 | Instruction Following | /shared-only/models/Qwen/Qwen3-4B-Thinking-2507 | Qwen | Latest instruction version July 2025 |
| Qwen3-4B-Thinking-2507 | Complex Reasoning | /shared-only/models/Qwen/Qwen3-4B-Instruct-2507 | Qwen | Chain-of-thought version July 2025 |
| Qwen3-Omni-30B-A3B-Instruct | Multimodal | /shared-only/models/Qwen/Qwen3-Omni-30B-A3B-Instruct | Qwen | Latest omnipotent multimodal |
| Qwen3-Omni-30B-A3B-Thinking | Multimodal Reasoning | /shared-only/models/Qwen/Qwen3-Omni-30B-A3B-Instruct | Qwen | Omnipotent multimodal CoT |
| Qwen3-VL-4B-Instruct | Vision Understanding | /shared-only/models/Qwen/Qwen3-VL-4B-Instruct | Qwen | Latest Qwen3 vision model |
| Qwen3-VL-4B-Thinking | Vision Reasoning | /shared-only/models/Qwen/Qwen3-VL-4B-Thinking | Qwen | Latest CoT vision model |
| Qwen3-VL-8B-Instruct | Vision Understanding | /shared-only/models/Qwen/Qwen3-VL-8B-Instruct | Qwen | Latest 8B vision model |
| Qwen3-VL-8B-Thinking | Vision Reasoning | /shared-only/models/Qwen/Qwen3-VL-8B-Thinking | Qwen | Latest 8B CoT vision |
| Qwen3-VL-30B-A3B-Instruct | Vision Understanding | /shared-only/models/Qwen/Qwen3-VL-30B-A3B-Instruct | Qwen | Latest MoE vision architecture |
| Qwen3-VL-30B-A3B-Thinking | Vision Reasoning | /shared-only/models/Qwen/Qwen3-VL-30B-A3B-Thinking | Qwen | Latest MoE CoT vision |
| Qwen3-VL-235B-A22B-Instruct | Vision Understanding | /shared-only/models/Qwen/Qwen3-VL-235B-A22B-Instruct | Qwen | Latest ultra-large vision |
| Qwen3-VL-235B-A22B-Thinking | Vision Reasoning | /shared-only/models/Qwen/Qwen3-VL-235B-A22B-Thinking | Qwen | Latest premier vision reasoning |
| DeepSeek-R1-0528-Qwen3-8B | Reasoning Enhancement | /shared-only/models/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B | DeepSeek | Reasoning model May 2025 |
| Kimi-VL-A3B-Thinking-2506 | Vision Reasoning | /shared-only/models/moonshotai/Kimi-VL-A3B-Thinking-2506 | Moonshot AI | CoT version June 2025 |
| LLaVA-NeXT-Video-34B-DPO-hf | Video Understanding | /shared-only/models/llava-hf/LLaVA-NeXT-Video-34B-DPO-hf | LLaVA | Latest DPO-optimized video |
| InternVL3-78B | Vision Understanding | /shared-only/models/OpenGVLab/InternVL3-78B | OpenGVLab | Latest large-scale vision model |
| Llama-4-Scout-17B-16E-Instruct | Multi-sensory Input | /shared-only/models/meta-llama/Llama-4-Scout-17B-16E-Instruct | Meta | Metaâ€™s latest multimodal |
| MiMo-7B-RL-0530 | Reinforcement Learning | /shared-only/models/XiaomiMiMo/MiMo-7B-RL-0530 | Xiaomi | RL version May 2025 |
| MiniCPM-V-4_5 | Vision Understanding | /shared-only/models/openbmb/MiniCPM-V-4_5 | OpenBMB | Latest lightweight vision |
| Ovis2.5-9B | General Modal | /shared-only/models/openbmb/MiniCPM-V-4_5 | OpenBMB | Latest general model |






## ğŸ“Š Industry-Specific Dataset Repository

The platform hosts an extensive collection of AI datasets. These datasets constitute a complete data ecosystem spanning from foundational pre-training to advanced task fine-tuning, supporting multilingual and multimodal LLM development and training. Click [Dataset List](./Extra-Chapter/datasetlList.md) to access more high-quality datasets for free.

**Pre-training** Datasets: Including wikipedia_zh, wikipedia_en, refinedweb, and redpajama_v2â€”massive, general-purpose corpora serving as the foundation for models to acquire language and world knowledge.

**Instruction Supervised Fine-tuning** Datasets: Represented by alpaca_en and alpaca_zh_demo, designed to teach models to understand and follow human instructions for dialogue and task execution.

**Tool-calling Fine-tuning** Datasets: Such as glaive_toolcall_en_demo and glaive_toolcall_zh_demo, specifically training models to understand external function invocation and handle returned results.

**Multimodal Fine-tuning** Datasets: Including mllm_audio_demo, mllm_video_demo, etc., correlating text with audio and video files to train models in processing and understanding multimodal information.

**Domain-specific Fine-tuning** Datasets: Examples include medical_o1_sft_Chinese_alpaca for healthcare, and identity for defining behavioral normsâ€”enhancing model expertise in vertical area or behavioral specifications.

These datasets collectively support the full development lifecycle of large language models, from general knowledge acquisition and conversational capability cultivation to specialized skill enhancement.

| Dataset Name | Size | Path | Publisher | Description |
| :--- | :--- | :--- | :--- | :--- |
| wikipedia_zh | 501MB | `/shared-only/datasets/pleisto/wikipedia-cn-20230720-filtered/wikipedia-cn-20230720-filtered.json` | pleisto | Filtered and processed Chinese Wikipedia data from July 20, 2023, suitable for Chinese model pre-training. |
| wikipedia_en | 12GB | `/shared-only/datasets/olm/olm-wikipedia-20221220/data/` | olm | English Wikipedia snapshot from December 20, 2022, high-quality knowledge-based pre-training corpus. |
| refinedweb | 568GB | `/shared-only/datasets/tiiuae/falcon-refinedweb/data/` | TII | High-quality web text created by TII for Falcon models, extensively filtered and deduplicatedâ€”one of the best open web corpora available. |
| redpajama_v2 | 114MB | `/shared-only/datasets/togethercomputer/RedPajama-Data-V2` | togethercomputer | A project aimed at fully open-sourcing LLaMA model training data replication, containing massive and diverse text and code. |
| medical_o1_sft_Chinese_alpaca | 49GB | `/shared-only/datasets/medical_o1_sft_Chinese_alpaca.json` | llamafactory | N/A |
| identity | 20KB | `/shared-only/datasets/identity.json` | llamafactory | Contains multilingual (Chinese and English) user queries and corresponding AI assistant response templates, covering AI assistant names and developer information. |
| alpaca_en | 22MB | `/shared-only/datasets/alpaca_data_en_52k.json` | llamafactory | Alpaca-format English instruction fine-tuning dataset, including user instructions, inputs, model responses, system prompts, and conversation history. |
| alpaca_zh_demo | 622KB | `/shared-only/datasets/alpaca_zh_demo.json` | llamafactory | Alpaca-format Chinese instruction fine-tuning dataset, containing instructions, inputs, responses, system prompts, and conversation history. |
| glaive_toolcall_en_demo | 722KB | `/shared-only/datasets/glaive_toolcall_en_demo.json` | llamafactory | ShareGPT-format English fine-tuning dataset with multi-role conversations (e.g., human, gpt, function_call). |
| glaive_toolcall_zh_demo | 722KB | `/shared-only/datasets/glaive_toolcall_zh_demo.json` | llamafactory | ShareGPT-format Chinese fine-tuning dataset with multi-role conversations (e.g., human, gpt, function_call). |
| mllm_audio_demo | 877B | `/shared-only/datasets/mllm_audio_demo.json` | llamafactory | ShareGPT-format multimodal audio dataset with conversations and audio paths for audio Q&A fine-tuning. |
| mllm_video_demo | 828B | `/shared-only/datasets/mllm_video_demo.json` | llamafactory | ShareGPT-format multimodal video dataset with video Q&A and video paths for video Q&A fine-tuning. |
| mllm_video_audio_demo | 1.1KB | `/shared-only/datasets/mllm_video_audio_demo.json` | llamafactory | ShareGPT-format multimodal audio-video dataset with audio-video Q&A and corresponding file paths for audio-video Q&A fine-tuning. |



## ğŸ’¡ How to Learn

### Target Audience
- ğŸ¤– **AI Engineers/Algorithm Engineers**: Seeking systematic mastery of LLM fine-tuning techniques
- ğŸ“ **Students/Researchers**: Requiring theoretical foundations and experimental guidance
- ğŸ¢ **Enterprise Technical Leaders**: Pursuing LLM implementation solutions
- ğŸ’» **Developers/Enthusiasts**: Interested in AI and eager to participate in open-source projects

### Recommended Learning Paths

#### Beginner Pathï¼ˆ2-3 weeks recommendedï¼‰
1. **Week 1**: Read Chapters 1-3 to establish foundational understanding of fine-tuning
2. **Week 2**: Study Chapter 5 and complete your first fine-tuning experiment
3. **Week 3**: Select an industry case of interest (Chapter 7) for hands-on practice

#### Intermediate Pathï¼ˆ1-2 weeks recommendedï¼‰
1. **Deep Learning**: Focus on technical details in Chapters 2, 4, and 8
2. **Systematic Practice**: Complete end-to-end projects using LlamaFactory Online
3. **Source Code Study**: Review complete code examples provided in the project

#### Expert Path
1. **Technical Innovation**: Research cutting-edge fine-tuning techniques in Chapter 2
2. **Performance Optimization**: Practice tuning techniques from Chapters 4 and 8
3. **Community Contribution**: Submit PRs to participate in the project

### Learning Recommendations
1. **Theory Meets Practice**: Each technical concept includes code examplesâ€”hands-on execution recommended
2. **Progressive Learning**: Follow chapter sequence to build solid foundations before advancing
3. **Community Engagement**: Promptly raise questions in the Issue section and actively participate in discussions
4. **Continuous Updates**: Monitor project updates to stay informed of latest technical developments

## ğŸ¤ How to Contribute

We warmly welcome contributions of all forms to build the best LLM fine-tuning learning resource together!

### ğŸ› Report Issues
- Found documentation errors or code bugs? Please submit an [Issue](https://github.com/LLaMAFactoryOnline/LLaMA-Factory-Online/issues).
- Provide detailed descriptions and reproduction stepsâ€”weâ€™ll address them promptly.

### ğŸ’¡ Suggest Improvements
- Have great ideas or feature suggestions? Weâ€™d love to hear them
- Including: new chapter proposals, technical supplements, case additions, etc.

### ğŸ“ Enhance Content
- Supplement missing technical details
- Optimize documentation clarity and readability
- Translate multilingual versions

### ğŸ”§ Code Contributions
- Fix code bugs
- Optimize algorithm implementations
- Add new example code

### ğŸ¢ Industry Case Contributions
- Share your industry fine-tuning practical experience
- Provide validated datasets and models
- Contribute enterprise-level application cases



### ğŸš€ Participation Steps
1. Fork this repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Submit a Pull Request

## ğŸ™ Acknowledgments

### Core Contribution Team
- **Project Initiator**ï¼šLLM-Cookbook Team




## â­ Support Us

If this project helps you, please give us a Star! â­
Your support is our greatest motivation for continuous updates!


## ğŸ“ Contact & Communication

### Official Platforms
- ğŸŒ **Official Website**: https://www.llamafactory.online/
- ğŸ’¬ **Online Documentation**: https://docs.llamafactory.online/
- ğŸ¥ **Video Tutorials**: https://space.bilibili.com/3546954208381522/upload/video
- ğŸ’¬ **WeChat Community**: (Scan QR code to add assistant, note â€œFine-tuning Guideâ€)




## ğŸ“œ Open Source License

This project is licensed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License**.

**You are free to:**
- Share â€” copy and redistribute the material in any medium or format
- Adapt â€” remix, transform, and build upon the material

**Under the following terms:**
- Attribution â€” You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
- NonCommercial â€” You may not use the material for commercial purposes.
- ShareAlike â€” If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.

---

**About LlamaFactory Online**  
LlamaFactory Online is an open-source platform for LLM fine-tuning and deployment, dedicated to lowering the barrier to LLM applications and enabling every developer to easily use and customize large language models. Complete fine-tuning tasks effortlessly through interactive parameter selection without writing code, supporting training methods like SFT and DPO, optimization algorithms including LoRA and Freeze, and providing high-performance GPUs for single-machine multi-card and multi-machine multi-card distributed training.

Scan the QR code to follow us for the latest technical updates and event information:

![alt text](/docs/images/1.jpg)


**Letâ€™s build a smarter future together!** ğŸš€